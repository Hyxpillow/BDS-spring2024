{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/06 18:24:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/local/bin/python3.11\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/local/bin/python3.11\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"movie recommendation\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = spark.read.load(\"datasets/movie_lens/movies.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "movies.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = spark.read.load(\"datasets/movie_lens/ratings.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "ratings.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of ratings per user is 20\n",
      "min # of ratings per movie is 1\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "user_groups = ratings.groupBy(\"userId\").count().toPandas()[\"count\"].min()\n",
    "movie_groups = ratings.groupBy(\"movieId\").count().toPandas()[\"count\"].min()\n",
    "print(\"min # of ratings per user is\", user_groups)\n",
    "print(\"min # of ratings per movie is\", movie_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3446 out of 9724 movies are rated by only one user\n"
     ]
    }
   ],
   "source": [
    "# check how many movies are rated by only one user\n",
    "count_single_rating_movies = ratings.groupBy(\"movieId\").count().filter(\"count = 1\").count()\n",
    "count_movies = ratings.select(\"movieId\").distinct().count()\n",
    "print(count_single_rating_movies, \"out of\", count_movies, \"movies are rated by only one user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotal number of users rated is 610\n",
      "total number of movies rated is 9724\n"
     ]
    }
   ],
   "source": [
    "# check the number of users and movies rated\n",
    "count_users_rated = ratings.select(\"userId\").distinct().count()\n",
    "count_movies_rated = ratings.select(\"movieId\").distinct().count()\n",
    "print(\"rotal number of users rated is\", count_users_rated)\n",
    "print(\"total number of movies rated is\", count_movies_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of movies is 9742\n",
      "total number of movies rated is 9724\n"
     ]
    }
   ],
   "source": [
    "# compare the number of movies in the movies.csv and ratings.csv, i.e. how many movies are not rated\n",
    "count_movies = movies.select(\"movieId\").distinct().count()\n",
    "count_movies_rated = ratings.select(\"movieId\").distinct().count()\n",
    "print(\"total number of movies is\", count_movies)\n",
    "print(\"total number of movies rated is\", count_movies_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies that are not rated yet: \n",
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|   1076|Innocents, The (1...|\n",
      "|   2939|      Niagara (1953)|\n",
      "|   3338|For All Mankind (...|\n",
      "|   3456|Color of Paradise...|\n",
      "|   4194|I Know Where I'm ...|\n",
      "|   5721|  Chosen, The (1981)|\n",
      "|   6668|Road Home, The (W...|\n",
      "|   6849|      Scrooge (1970)|\n",
      "|   7020|        Proof (1991)|\n",
      "|   7792|Parallax View, Th...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all unrated movies\n",
    "movies.createOrReplaceTempView(\"movies\")\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "print(\"movies that are not rated yet: \")\n",
    "spark.sql(\n",
    "    \"SELECT m.movieId, m.title \"\n",
    "    \"FROM movies m LEFT JOIN ratings r ON m.movieId=r.movieId \"\n",
    "    \"WHERE r.movieId IS NULL\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, 4.0), (1, 3, 4.0), (1, 6, 4.0)]\n"
     ]
    }
   ],
   "source": [
    "movie_ratings = sc.textFile(\"datasets/movie_lens/ratings.csv\")\n",
    "\n",
    "header = movie_ratings.first()\n",
    "ratings_data = movie_ratings \\\n",
    "    .filter(lambda line: line != header) \\\n",
    "    .map(lambda line: line.split(\",\")) \\\n",
    "    .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))) \\\n",
    "    .cache()\n",
    "\n",
    "print(ratings_data.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[115] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validation, test = ratings_data.randomSplit([6, 2, 2], seed=42)\n",
    "train.cache()\n",
    "validation.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/06 18:24:40 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/06 18:24:41 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/05/06 18:24:41 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "100%|█████████████████████████████████████████████████| 7/7 [02:28<00:00, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best model has 8 latent factors and regularization = 0.2, with RMSE = 0.8906498894233397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "ranks = [8, 10, 12, 14, 16, 18, 20]\n",
    "reg_params = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "min_error = float(\"inf\")\n",
    "best_rank = -1\n",
    "best_regularization = 0\n",
    "best_model = None\n",
    "best_rmse = float(\"inf\")\n",
    "\n",
    "for rank in tqdm.tqdm(ranks, total=len(ranks)):\n",
    "    for reg in reg_params:\n",
    "        model = ALS.train(\n",
    "            ratings=train,\n",
    "            iterations=num_iterations,\n",
    "            rank=rank,\n",
    "            lambda_=reg,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        valid_data = validation.map(lambda p: (p[0], p[1]))\n",
    "        predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "        rates_and_preds = validation.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "\n",
    "        MSE = rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "        error = math.sqrt(MSE)\n",
    "\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_rank = rank\n",
    "            best_regularization = reg\n",
    "            best_model = model\n",
    "            best_rmse = error\n",
    "\n",
    "print(\"\\nThe best model has {} latent factors and regularization = {}, with RMSE = {}\".format(best_rank, best_regularization, best_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/06 18:27:05 WARN BlockManager: Task 8362 already completed, not releasing lock for rdd_111_0\n",
      "[Stage 6494:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.7349596832883968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_model = ALS.train(\n",
    "    ratings=ratings_data,\n",
    "    iterations=num_iterations,\n",
    "    rank=best_rank,\n",
    "    lambda_=best_regularization,\n",
    "    seed=42\n",
    ")\n",
    "test_data = test.map(lambda p: (p[0], p[1]))\n",
    "predictions = final_model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "error = math.sqrt(MSE)\n",
    "print(\"For testing data the RMSE is {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Toy Story:\n",
      "1: Hoop Dreams (1994)\n",
      "2: Star Wars: Episode IV - A New Hope (1977)\n",
      "3: Shawshank Redemption, The (1994)\n",
      "4: Schindler's List (1993)\n",
      "5: Philadelphia Story, The (1940)\n",
      "6: It's a Wonderful Life (1946)\n",
      "7: Amadeus (1984)\n",
      "8: Gandhi (1982)\n",
      "9: General, The (1926)\n",
      "10: Yojimbo (1961)\n"
     ]
    }
   ],
   "source": [
    "movies_df = spark.read.load(\"datasets/movie_lens/movies.csv\", format=\"csv\", header=True, inferSchema=True)\n",
    "ratings_rdd = spark.read.load(\"datasets/movie_lens/ratings.csv\", format=\"csv\", header=True, inferSchema=True) \\\n",
    "                      .rdd.map(lambda row: (row[\"userId\"], row[\"movieId\"], row[\"rating\"]))\n",
    "\n",
    "favorites = [\"Toy Story\"]\n",
    "\n",
    "favorite_ids = []\n",
    "for fav in favorites:\n",
    "    ids = movies_df \\\n",
    "        .filter(movies_df.title.like(\"%{}%\".format(fav))) \\\n",
    "        .select(\"movieId\") \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: r[0]) \\\n",
    "        .collect()\n",
    "    favorite_ids.extend(ids)\n",
    "favorite_ids = list(set(favorite_ids))\n",
    "\n",
    "new_user_id = ratings_rdd.map(lambda r: r[0]).max() + 1\n",
    "highest_rating = ratings_rdd.map(lambda r: r[2]).max()\n",
    "new_user_data = [(new_user_id, movieId, highest_rating) for movieId in favorite_ids]\n",
    "new_user_rdd = sc.parallelize(new_user_data)\n",
    "training_data = ratings_rdd.union(new_user_rdd)\n",
    "\n",
    "model = ALS.train(\n",
    "    ratings=training_data,\n",
    "    iterations=10,\n",
    "    rank=20,\n",
    "    lambda_=0.05,\n",
    "    seed=99\n",
    ")\n",
    "\n",
    "inference_rdd = movies_df.rdd \\\n",
    "    .map(lambda r: r[\"movieId\"]) \\\n",
    "    .distinct() \\\n",
    "    .filter(lambda x: x not in favorite_ids) \\\n",
    "    .map(lambda x: (new_user_id, x))\n",
    "\n",
    "predictions = model.predictAll(inference_rdd).map(lambda r: (r[1], r[2]))\n",
    "top_10 = predictions.sortBy(lambda r: r[1], ascending=False).take(10)\n",
    "top_10_ids = [r[0] for r in top_10]\n",
    "\n",
    "recommendations = movies_df.filter(movies_df.movieId.isin(top_10_ids)) \\\n",
    "                           .select(\"title\") \\\n",
    "                           .rdd \\\n",
    "                           .map(lambda r: r[0]) \\\n",
    "                           .collect()\n",
    "\n",
    "print(f\"Recommendations for {favorites[0]}:\")\n",
    "for i, title in enumerate(recommendations):\n",
    "    print(f\"{i+1}: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
